{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94bd545",
   "metadata": {},
   "source": [
    "# q3fer/distilbert-base-fallacy-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cda090",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27790c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, TextClassificationPipeline \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix\n",
    "import mlflow\n",
    "from mlflow.transformers import log_model\n",
    "import logging \n",
    "from logging import getLogger\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#  import pickle\n",
    "import warnings # why? \n",
    "from mlflow.sklearn import save_model \n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # This tells Hugging Face: “Don’t use parallel tokenization — avoid possible deadlocks.”\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d73bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from basic_functions import (\n",
    "    get_eval_metrics,\n",
    "    createTrainer, \n",
    "    get_encode_tokenize_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9709ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"q3fer/distilbert-base-fallacy-classification\" # pulls the fallacy trained model\n",
    "TRACKING_URI = config.TRACKING_URI\n",
    "EXPERIMENT_NAME = config.EXPERIMENT_NAME\n",
    "configuration = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s: %(message)s\") # Configure logging format to show timestamp before every message\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO) # Only show logs that are INFO or more important (e.g., WARNING, ERROR) — but ignore DEBUG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeba3e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Label ID to Label Mapping:\n",
      "{0: 'ad hominem', 1: 'ad populum', 2: 'appeal to emotion', 3: 'circular reasoning', 4: 'equivocation', 5: 'fallacy of credibility', 6: 'fallacy of extension', 7: 'fallacy of logic', 8: 'fallacy of relevance', 9: 'false causality', 10: 'false dilemma', 11: 'faulty generalization', 12: 'intentional', 13: 'miscellaneous'}\n",
      "\n",
      "Reverse Mapping (Label to ID):\n",
      "{'ad hominem': 0, 'ad populum': 1, 'appeal to emotion': 2, 'circular reasoning': 3, 'equivocation': 4, 'fallacy of credibility': 5, 'fallacy of extension': 6, 'fallacy of logic': 7, 'fallacy of relevance': 8, 'false causality': 9, 'false dilemma': 10, 'faulty generalization': 11, 'intentional': 12, 'miscellaneous': 13}\n"
     ]
    }
   ],
   "source": [
    "# Load model config to inspect label mappings\n",
    "\n",
    "print(\"Model Label ID to Label Mapping:\")\n",
    "print(configuration.id2label)\n",
    "\n",
    "print(\"\\nReverse Mapping (Label to ID):\")\n",
    "print(configuration.label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d142a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/data_dropped_duplicates_small.csv\"\n",
    "MODEL_PATH = \"q3fer/distilbert-base-fallacy-classification\"\n",
    "MODEL_TRAINING_PATH =\"q3fer/distilbert-base-fallacy-classification\"\n",
    "OUTPUT_DIR = \"../models/q3fer/distilbert-base-fallacy-classification/trainer_output\"\n",
    "SAVE_PATH = \"../models/q3fer/distilbert-base-fallacy-classification/pytorch_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f12ffd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/data_dropped_duplicates_small.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f31bd6",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1d16ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:basic_functions:../data/data_dropped_duplicates_small.csv\n",
      "INFO:basic_functions:q3fer/distilbert-base-fallacy-classification\n",
      "INFO:basic_functions:Loading data...\n",
      "INFO:basic_functions:0                  ad_hominem\n",
      "1                        none\n",
      "2           appeal_to_emotion\n",
      "3           appeal_to_emotion\n",
      "4       faulty_generalization\n",
      "                ...          \n",
      "4995        appeal_to_emotion\n",
      "4996    faulty_generalization\n",
      "4997               ad_hominem\n",
      "4998                     none\n",
      "4999                     none\n",
      "Name: logical_fallacies, Length: 5000, dtype: object\n",
      "INFO:basic_functions:Train test split, test-size 0.3\n",
      "INFO:root:encode the label column\n",
      "INFO:root:tokenize\n",
      "INFO:basic_functions:create tokenizer & load model\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alicepope/.pyenv/versions/3.11.3/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alicepope/.pyenv/versions/3.11.3/lib/python3.11/logging/__init__.py\", line 953, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alicepope/.pyenv/versions/3.11.3/lib/python3.11/logging/__init__.py\", line 687, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/alicepope/.pyenv/versions/3.11.3/lib/python3.11/logging/__init__.py\", line 377, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/alicepope/.pyenv/versions/3.11.3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/alicepope/.pyenv/versions/3.11.3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/alicepope/.pyenv/versions/3.11.3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/qt/8rxmyyc907sdnc599f4rg0080000gn/T/ipykernel_13898/2160959213.py\", line 1, in <module>\n",
      "    train_dataset, test_dataset, y_train, le = get_encode_tokenize_data(DATA_PATH, MODEL_PATH)\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/modeling/basic_functions.py\", line 93, in get_encode_tokenize_data\n",
      "    train_encodings = tokenize(X_train.to_list(), model_path)\n",
      "  File \"/Users/alicepope/Capstone project/Capstone_project/backend/modeling/basic_functions.py\", line 40, in tokenize\n",
      "    logger.info(\"Model path:\", model_path)\n",
      "Message: 'Model path:'\n",
      "Arguments: ('q3fer/distilbert-base-fallacy-classification',)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_dataset, test_dataset, y_train, le = \u001b[43mget_encode_tokenize_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Capstone project/Capstone_project/backend/modeling/basic_functions.py:93\u001b[39m, in \u001b[36mget_encode_tokenize_data\u001b[39m\u001b[34m(path, model_path)\u001b[39m\n\u001b[32m     89\u001b[39m y_test = le.transform(y_test)\n\u001b[32m     92\u001b[39m logging.info(\u001b[33m'\u001b[39m\u001b[33mtokenize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m train_encodings = \u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m test_encodings = tokenize(X_test.to_list(), model_path)\n\u001b[32m     96\u001b[39m logging.info(\u001b[33m'\u001b[39m\u001b[33mcreate TextDatasets (train & test)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Capstone project/Capstone_project/backend/modeling/basic_functions.py:43\u001b[39m, in \u001b[36mtokenize\u001b[39m\u001b[34m(texts, model_path)\u001b[39m\n\u001b[32m     40\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mModel path:\u001b[39m\u001b[33m\"\u001b[39m, model_path)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# tokenization after train test split to prevent data leakage\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m#added use_fast=False to prevent tokenization error (might happen when using fast tokenization)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mGot out the tokenizer.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(\n\u001b[32m     46\u001b[39m     texts,\n\u001b[32m     47\u001b[39m     padding=\u001b[33m\"\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;66;03m#ensures that all tokenized sequences are padded to the same length, padding adds special tokens to shorter sequeces so they match the maximum length\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m#converts the output to pytorch tensors\u001b[39;00m\n\u001b[32m     51\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:973\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    970\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    971\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist or is not currently imported.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    972\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m973\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[32m    976\u001b[39m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2062\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2059\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2060\u001b[39m         logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2062\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2071\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2073\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2302\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._from_pretrained\u001b[39m\u001b[34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2300\u001b[39m \u001b[38;5;66;03m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[32m   2301\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2302\u001b[39m     tokenizer = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2303\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m import_protobuf_decode_error():\n\u001b[32m   2304\u001b[39m     logger.info(\n\u001b[32m   2305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to load tokenizer model from SPM, loading from TikToken will be attempted instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(Google protobuf error: Tried to load SPM model with non-SPM vocab file).\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2307\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Capstone project/Capstone_project/backend/.venv/lib/python3.11/site-packages/transformers/models/distilbert/tokenization_distilbert.py:117\u001b[39m, in \u001b[36mDistilBertTokenizer.__init__\u001b[39m\u001b[34m(self, vocab_file, do_lower_case, do_basic_tokenize, never_split, unk_token, sep_token, pad_token, cls_token, mask_token, tokenize_chinese_chars, strip_accents, clean_up_tokenization_spaces, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    103\u001b[39m     vocab_file,\n\u001b[32m   (...)\u001b[39m\u001b[32m    115\u001b[39m     **kwargs,\n\u001b[32m    116\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    118\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    119\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find a vocabulary file at path \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocab_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. To load the vocabulary from a Google pretrained\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m model use `tokenizer = DistilBertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    121\u001b[39m         )\n\u001b[32m    122\u001b[39m     \u001b[38;5;28mself\u001b[39m.vocab = load_vocab(vocab_file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen genericpath>:30\u001b[39m, in \u001b[36misfile\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: stat: path should be string, bytes, os.PathLike or integer, not NoneType"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, y_train, le = get_encode_tokenize_data(DATA_PATH, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and preprocess data\n",
    "# logger.info(\"Loading and preprocessing data...\")\n",
    "# df = pd.read_csv(DATA_PATH)\n",
    "# le = LabelEncoder()\n",
    "# df[\"label\"] = le.fit_transform(df[\"logical_fallacies\"])\n",
    "# dataset = Dataset.from_pandas(df[[\"text\", \"label\"]])\n",
    "# dataset = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# def tokenize(batch):\n",
    "#     return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "# dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking the labels\n",
    "# print(le.classes_)  \n",
    "# print(le.inverse_transform([0,1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0740229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new labels\n",
    "id2label = {\n",
    "    0: \"ad_hominem\",\n",
    "    1: \"appeal_to_authority\",\n",
    "    2: \"appeal_to_emotion\",\n",
    "    3: \"false_dilemma\",\n",
    "    4: \"faulty_generalization\",\n",
    "    5: \"none\"\n",
    "}\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd46821",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981718bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=num_classes,\n",
    "    ignore_mismatched_sizes= True\n",
    "    )\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e23fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = model.classifier\n",
    "# Check the size of the weights\n",
    "print(final_layer.weight.shape)  # Will be [num_labels, hidden_size] (num_labels x hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see a summary of the model\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7558dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "      \"learning_rate\": 5e-5,\n",
    "      \"weight_decay\": 0.01,\n",
    "      \"num_train_epochs\": 3,\n",
    "      \"evaluation_strategy\": \"epoch\",\n",
    "      \"class_weight\":True,\n",
    "  }\n",
    "\n",
    "\n",
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "\n",
    "mlflow.start_run()\n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "\n",
    "mlflow.set_tag(\"model_name\", MODEL_NAME)\n",
    "mlflow.log_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = createTrainer(\n",
    "    model= model, \n",
    "    train_dataset = train_dataset,\n",
    "    test_dataset = test_dataset,\n",
    "    output_dir= OUTPUT_DIR, \n",
    "    y_train=y_train, \n",
    "    class_weight=True, \n",
    "    epochs=3, \n",
    "    learning_rate=5e-5, \n",
    "    weight_decay = 0.01, \n",
    "    train_batch_size=4, \n",
    "    eval_batch_size=8 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4271cb9a",
   "metadata": {},
   "source": [
    "### Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()  # Clears unused GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable upper limit for memory\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "# Allows up to 100% of available memory\n",
    "torch.mps.set_per_process_memory_fraction(1.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c00ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('training is running')\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edda4f01",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e808b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prediction and reporting here\n",
    "output = trainer.predict(dataset[\"test\"])\n",
    "predictions = np.argmax(output.predictions, axis=1)\n",
    "y_true = output.label_ids\n",
    "\n",
    "# Classification report\n",
    "label_names = le.classes_\n",
    "print(classification_report(y_true, predictions, target_names=label_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_names, yticklabels=label_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d4317",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../models/distilbert-base-fallacy-classification\"\n",
    "save_model(sk_model=model, path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff82fd",
   "metadata": {},
   "source": [
    "### Checking the q3fer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a61895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference with q3fer model on sample texts\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "examples = [\n",
    "    \"You have no idea what you're talking about; you've only lived here for six months.\", # ad_hominem\n",
    "    \"I read a book by a nutritionist who says all carbs are bad.\", # appeal_to_authority\n",
    "    \"Can I have the last piece of cake? You know how much I love it, and it's been a tough day for me.\", # appeal_to_emotion\n",
    "    \"If we don't order pizza for dinner, we'll have to eat the week-old spaghetti in the fridge.\", # false_dilemma\n",
    "    \"I was in Greece for two week. Greeks are amazing people!\", # faulty_generalization\n",
    "    \"We should look into the science that supports this idea.\" # none\n",
    "]\n",
    "\n",
    "predictions = pipeline(examples)\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Text {i+1}: {examples[i]}\")\n",
    "    print(f\"Prediction: {pred['label']} (Score: {pred['score']:.2f})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'ad hominem': 'ad_hominem',\n",
    "    'appeal to emotion': 'appeal_to_emotion',\n",
    "    'false dilemma': 'false_dilemma',\n",
    "    'faulty generalization': 'faulty_generalization',\n",
    "    'circular reasoning': 'other',\n",
    "    'appeal to authority': 'appeal_to_authority',  \n",
    "    'miscellaneous': 'other',  \n",
    "    'fallacy of logic': 'other',\n",
    "    'intentional': 'other',\n",
    "    'ad populum': 'other',\n",
    "    'equivocation': 'other',\n",
    "    'false causality': 'other',\n",
    "    'fallacy of relevance': 'other',\n",
    "    'fallacy of credibility': 'other',\n",
    "    'fallacy of extension': 'other'\n",
    "}\n",
    "\n",
    "#  the model's label doesn't include 'none'.Maybe we should/could test it out on our dataset with only the fallacies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with the examples\n",
    "mapped_predictions = []\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    original_label = pred['label']\n",
    "    mapped_label = label_mapping.get(original_label, 'unmapped')\n",
    "\n",
    "    print(f\"Text {i+1}: {examples[i]}\")\n",
    "    print(f\"Original Prediction: {original_label} (Score: {pred['score']:.2f})\")\n",
    "    print(f\"Mapped to: {mapped_label}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    mapped_predictions.append(mapped_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
