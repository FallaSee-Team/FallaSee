{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Basic Model: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import nltk\n",
    "\n",
    "import mlflow\n",
    "import logging \n",
    "import modeling.config \n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from modeling.basic_functions import (\n",
    "    get_preprocess_data,\n",
    "    get_lemmatized_data,\n",
    "    get_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Naive_Bayes_oversampling\" \n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "EXPERIMENT_NAME = modeling.config.EXPERIMENT_NAME\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s: %(message)s\") # Configure logging format to show timestamp before every message\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO) # Only show logs that are INFO or more important (e.g., WARNING, ERROR) â€” but ignore DEBUG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/data_dropped_duplicates_small.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_preprocess_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_lemmatized_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"logical_fallacies\"]\n",
    "X = df[\"text\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run()\n",
    "run = mlflow.active_run()\n",
    "mlflow.set_tag(\"model_name\", MODEL_NAME)\n",
    "mlflow.set_tag(\"mlflow.runName\", \"naive bayes oversampling\")\n",
    "# mlflow.log_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use TF-IDF Vecorizer to transform text into numerical data\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "# X_vectorized_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Oversampling only on train dataset\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# X_resampled_train, y_resampled_train = ros.fit_resample(X_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# # Define the parameter grid for Naive Bayes\n",
    "# param_grid = {\n",
    "#     'alpha': [0.1, 0.5, 1.0, 2.0],  # Smoothing parameter\n",
    "#     'fit_prior': [True, False]       # Whether to learn class priors from data\n",
    "# }\n",
    "\n",
    "# # # Create a custom scoring function for macro F1\n",
    "# # macro_f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# # Initialize Naive Bayes model\n",
    "# nb = MultinomialNB()\n",
    "\n",
    "# # Set up GridSearchCV with macro F1 scoring\n",
    "# grid_search = GridSearchCV(nb, param_grid, cv=5, scoring=\"f1_weighted\")\n",
    "# grid_search.fit(X_resampled_train, y_resampled_train)\n",
    "\n",
    "# # Get best parameters and model\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best parameters:\", best_params)\n",
    "\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# # Predict on train and test data\n",
    "# y_train_pred = best_model.predict(X_resampled_train)\n",
    "# y_test_pred = best_model.predict(X_vectorized_test)\n",
    "\n",
    "# # Log parameters to MLflow\n",
    "# mlflow.log_params(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Gridsearch in Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline for TF-IFD and Naive Bayes\n",
    "pipeline_bayes = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('ros', RandomOverSampler(random_state=10)),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on the resampled training data\n",
    "X_res, y_res = pipeline_bayes.named_steps['ros'].fit_resample(\n",
    "    pipeline_bayes.named_steps['tfidf'].transform(X_train), \n",
    "    y_train\n",
    ")\n",
    "y_res_pred = pipeline_bayes.named_steps['nb'].predict(X_res)\n",
    "\n",
    "# Predict on test data\n",
    "y_test_pred = pipeline_bayes.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(cr, split):\n",
    "    for key, value in cr.items():\n",
    "        if (key == \"accuracy\"):\n",
    "                # print(f\"{split}_{key}\", round(value,2))\n",
    "                mlflow.log_metric(f\"{split}_{key}\", value)\n",
    "        else:\n",
    "            for metric in value:\n",
    "                mlflow.log_metric(f\"{split}_{key}_{metric}\", value.get(metric))\n",
    "                # print(f\"{split}_{key}_{metric}\", round(value.get(metri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('get_train_metrics')\n",
    "classification_report_train = get_metrics(y_res, y_res_pred)\n",
    "log_metrics(classification_report_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('get_test_metrics')\n",
    "classification_report_test = get_metrics(y_test, y_test_pred)\n",
    "log_metrics(classification_report_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
