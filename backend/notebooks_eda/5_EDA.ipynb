{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_type</th>\n",
       "      <th>claim</th>\n",
       "      <th>logical_fallacies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [claim_type, claim, logical_fallacies]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid = pd.DataFrame(columns=['claim_type', 'claim', 'logical_fallacies'])\n",
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallacies = ['Cherry Picking', 'Evading the Burden of Proof', 'False Analogy', 'False Authority', 'False Cause', 'Hasty Generalization', 'No Fallacy', 'Post Hoc', 'Red Herring', 'Strawman', 'Vagueness']\n",
    "set = ['train', 'test', 'dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in set:\n",
    "    for f in fallacies:\n",
    "        df_current = pd.read_csv(f'../data/rawdata/5_covid_{s}/{f}.tsv', sep='\\t')\n",
    "        df_current['logical_fallacies'] = f\n",
    "        df_covid = pd.concat([df_covid, df_current])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 154 entries, 0 to 1\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   claim_type         154 non-null    object\n",
      " 1   claim              154 non-null    object\n",
      " 2   logical_fallacies  154 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cherry Picking', 'Evading the Burden of Proof', 'False Analogy',\n",
       "       'False Authority', 'False Cause', 'Hasty Generalization',\n",
       "       'No Fallacy', 'Post Hoc', 'Red Herring', 'Strawman', 'Vagueness'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid['logical_fallacies'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logical_fallacies\n",
       "No Fallacy                     62\n",
       "Evading the Burden of Proof    14\n",
       "Cherry Picking                 13\n",
       "Post Hoc                       13\n",
       "False Authority                10\n",
       "Red Herring                     9\n",
       "False Analogy                   8\n",
       "Hasty Generalization            7\n",
       "Vagueness                       7\n",
       "False Cause                     6\n",
       "Strawman                        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid['logical_fallacies'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cherry Picking :\n",
      "In November 2020, Ticketmaster announced that it planned to require event attendees to verify that they have tested negative for the novel coronavirus within a 72-hour time frame.\n",
      "Cherry Picking :\n",
      "Says that “the way to reach ‘herd immunity’ is for >70% of the population to get vaccinated.”\n",
      "Cherry Picking :\n",
      "The public won’t be able to claim compensation if unlicensed vaccines damage our health.\n",
      "Cherry Picking :\n",
      "“vaccinated children appear to be significantly less healthy than the unvaccinated”\n",
      "Cherry Picking :\n",
      "The WHO now says a child’s presence in school counts as “informed consent” for a vaccination and parental presence is not required.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in np.arange(0,5,1):\n",
    "    print(df_covid.iloc[i, 2], ':')\n",
    "    print(df_covid.iloc[i, 1])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.to_csv('../data/cleaned/5_covid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_checked_segment</th>\n",
       "      <th>comment_by_fact-checker</th>\n",
       "      <th>article</th>\n",
       "      <th>logical_fallacies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fact_checked_segment, comment_by_fact-checker, article, logical_fallacies]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_climate = pd.DataFrame(columns=['fact_checked_segment', 'comment_by_fact-checker', 'article', 'logical_fallacies'])\n",
    "df_climate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in set:\n",
    "    for f in fallacies:\n",
    "        df_current = pd.read_csv(f'../data/rawdata/5_climate_{s}/{f}.tsv', sep='\\t')\n",
    "        df_current['logical_fallacies'] = f\n",
    "        df_climate = pd.concat([df_climate, df_current])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 685 entries, 0 to 11\n",
      "Data columns (total 4 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   fact_checked_segment     683 non-null    object\n",
      " 1   comment_by_fact-checker  684 non-null    object\n",
      " 2   article                  374 non-null    object\n",
      " 3   logical_fallacies        685 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 26.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_climate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logical_fallacies\n",
       "No Fallacy                     208\n",
       "Cherry Picking                 105\n",
       "Vagueness                       74\n",
       "Red Herring                     69\n",
       "False Authority                 50\n",
       "Evading the Burden of Proof     48\n",
       "False Cause                     46\n",
       "Strawman                        36\n",
       "False Analogy                   27\n",
       "Post Hoc                        14\n",
       "Hasty Generalization             8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_climate['logical_fallacies'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fact_checked_segment</th>\n",
       "      <th>comment_by_fact-checker</th>\n",
       "      <th>article</th>\n",
       "      <th>logical_fallacies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“climate economists see a positive externality...</td>\n",
       "      <td>This is cherry-picking at its worst. You can a...</td>\n",
       "      <td>article36.txt</td>\n",
       "      <td>Cherry Picking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The latest U.N. science compendium asserts tha...</td>\n",
       "      <td>The recent US National Climate Assessment1 fin...</td>\n",
       "      <td>article130.txt</td>\n",
       "      <td>Cherry Picking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                fact_checked_segment   \n",
       "0  “climate economists see a positive externality...  \\\n",
       "1  The latest U.N. science compendium asserts tha...   \n",
       "\n",
       "                             comment_by_fact-checker         article   \n",
       "0  This is cherry-picking at its worst. You can a...   article36.txt  \\\n",
       "1  The recent US National Climate Assessment1 fin...  article130.txt   \n",
       "\n",
       "  logical_fallacies  \n",
       "0    Cherry Picking  \n",
       "1    Cherry Picking  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_climate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cherry Picking :\n",
      "“climate economists see a positive externality, not a negative one, from the human influence on climate. (In technical lingo, the so-called social cost of carbon would be negative.)”\n",
      "Cherry Picking :\n",
      "The latest U.N. science compendium asserts that the latter half-degree is at least half manmade.\n",
      "Cherry Picking :\n",
      "“‘If we are right, our study challenges decades of paleoclimate research,” said Anders Meibom, the head of EPFL’s Laboratory for Biological Geochemistry and a professor at the University of Lausanne.”\n",
      "Cherry Picking :\n",
      "“a killer analysis conducted by Craig Idso of all the studies which have been done on the effects of reduced pH levels on marine life.”\n",
      "Cherry Picking :\n",
      "“Next year or the year after that, I think it will be free of ice in summer and by that I mean the central Arctic will be ice-free. You will be able to cross over the north pole by ship. There will still be about a million square kilometres of ice in the Arctic in summer but it will be packed into various nooks and crannies”\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in np.arange(0,5,1):\n",
    "    print(df_climate.iloc[i, 3], ':')\n",
    "    print(df_climate.iloc[i, 0])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climate.to_csv('../data/cleaned/5_climate.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic\n",
    "<span style='color:red'>It's the same as LogicClimate from Jin et al!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argotario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logical_fallacies</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Appeal to Emotion</td>\n",
       "      <td>No, imagine you were a teacher and everybody w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red Herring</td>\n",
       "      <td>The moon is so far away, we should focus on ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Irrelevant Authority</td>\n",
       "      <td>The green party in Germany has the opinion, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red Herring</td>\n",
       "      <td>No, not at all. Nowadays kids spend all time p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Fallacy</td>\n",
       "      <td>Yes,  whoever drinks and drives has a bad reac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               logical_fallacies   \n",
       "Row number                         \n",
       "0              Appeal to Emotion  \\\n",
       "1                    Red Herring   \n",
       "2           Irrelevant Authority   \n",
       "3                    Red Herring   \n",
       "4                     No Fallacy   \n",
       "\n",
       "                                                        claim  \n",
       "Row number                                                     \n",
       "0           No, imagine you were a teacher and everybody w...  \n",
       "1           The moon is so far away, we should focus on ou...  \n",
       "2           The green party in Germany has the opinion, th...  \n",
       "3           No, not at all. Nowadays kids spend all time p...  \n",
       "4           Yes,  whoever drinks and drives has a bad reac...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arg = pd.read_csv(f'../data/rawdata/5_argotario.tsv', sep='\\t', index_col=0)\n",
    "df_arg = df_arg[['Intended Fallacy', 'Text']]\n",
    "df_arg = df_arg.rename(columns={\"Intended Fallacy\": \"logical_fallacies\", \"Text\": \"claim\"})\n",
    "df_arg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1344 entries, 0 to 1337\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   logical_fallacies  1338 non-null   object\n",
      " 1   claim              1338 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_arg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Appeal to Emotion', 'Red Herring', 'Irrelevant Authority',\n",
       "       'No Fallacy', 'Ad Hominem', 'Hasty Generalization', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arg['logical_fallacies'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logical_fallacies\n",
       "No Fallacy              429\n",
       "Appeal to Emotion       236\n",
       "Red Herring             193\n",
       "Ad Hominem              166\n",
       "Irrelevant Authority    157\n",
       "Hasty Generalization    157\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arg['logical_fallacies'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appeal to Emotion :\n",
      "No, imagine you were a teacher and everybody would just concentrate on their smartphones? How would that feel?\n",
      "Red Herring :\n",
      "The moon is so far away, we should focus on our society.\n",
      "Irrelevant Authority :\n",
      "The green party in Germany has the opinion, that nuclear reactors are bad for us. It is not ok\n",
      "Red Herring :\n",
      "No, not at all. Nowadays kids spend all time playing around with tablets and smartphones, which is kinda detrimental to their proper development.\n",
      "No Fallacy :\n",
      "Yes,  whoever drinks and drives has a bad reaction time. People might die.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i in np.arange(0,5,1):\n",
    "    print(df_arg.iloc[i, 0], ':')\n",
    "    print(df_arg.iloc[i, 1])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arg.to_csv('../data/cleaned/7_argotario.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
