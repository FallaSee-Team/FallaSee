{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= ['dataset','text', 'logical_fallacies', 'source']\n",
    "df = pd.DataFrame(columns= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('../data/cleaned/1_logicClimate.csv')\n",
    "df_2 = pd.read_csv('../data/cleaned/2_Huggingface_dataset.csv', index_col=0)\n",
    "df_3 = pd.read_csv('../data/cleaned/3_CoCoLoFa_merged.csv')\n",
    "df_4 = pd.read_csv('../data/cleaned/4_falcon_df_multilabel_annotations.csv')\n",
    "df_5_1 = pd.read_csv('../data/cleaned/5_climate.csv')\n",
    "df_5_2 = pd.read_csv('../data/cleaned/5_covid.csv')\n",
    "df_6 = pd.read_csv('../data/cleaned/6_MAFALDA.csv')\n",
    "# df_7 = pd.read_csv('../data/cleaned/7_Reddit_dataset.csv', index_col=0) #identical to 4\n",
    "df_8 = pd.read_csv('../data/cleaned/8_argotario.csv')\n",
    "df_9 = pd.read_csv('../data/cleaned/9_Goffredo_used_in_MAFALDA_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_1['dataset']=1\n",
    "df_1 = df_1.rename(columns={ 'original_url': 'source', 'source_article': 'text'})\n",
    "df_1 = df_1.loc[:,cols ]\n",
    "df_1 = df_1[df_1['logical_fallacies']!='fallacy of logic']\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_2['dataset']=2\n",
    "df_2 = df_2.rename(columns={ 'statement': 'text', 'label': 'logical_fallacies'})\n",
    "df_2 = df_2.loc[:,['dataset', 'text', 'logical_fallacies']]\n",
    "df_2 = df_2[df_2['logical_fallacies']!='fallacy of logic']\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_3[['fallacy', 'comment']]\n",
    "df_3 = df_3.rename(columns={'fallacy':'logical_fallacies', 'comment': 'text' })\n",
    "df_3['dataset'] = 3\n",
    "df_3 = df_3.loc[:,['dataset','text', 'logical_fallacies']]\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_4 = df_4[['fallacy','main_tweet']]\n",
    "df_4 = df_4.rename(columns={'fallacy':'logical_fallacies','main_tweet': 'text' })\n",
    "df_4.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "df_splitted_fallacies = pd.DataFrame(columns=['logical_fallacies', 'text'])\n",
    "rows_to_delete=[]\n",
    "\n",
    "for i in range(len(df_4)):\n",
    "    # print(i)\n",
    "    current_fallacies = df_4.iloc[i, 0]\n",
    "    # print('current_fallacies:', current_fallacies)\n",
    "    current_fallacies = current_fallacies.replace(\"'\", \"\").replace('[', '').replace(']','')\n",
    "    splitted_fallacies = current_fallacies.split(sep=',')\n",
    "    if len(splitted_fallacies)==1:\n",
    "        df_4.iloc[i, 0] = current_fallacies\n",
    "    if len(splitted_fallacies)>1:\n",
    "        for index, f in enumerate(splitted_fallacies):\n",
    "            new_row = {'logical_fallacies':f, 'text': df_4.iloc[i, 1]}\n",
    "            df_splitted_fallacies = pd.concat([df_splitted_fallacies, pd.DataFrame([new_row])])\n",
    "            rows_to_delete.append(i)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    " #remove duplicates\n",
    "rows_to_delete = list(set(rows_to_delete))\n",
    "\n",
    "#drop rows with multilabels\n",
    "df_4 = df_4.drop(axis=0, index=rows_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate new rows to dataframe\n",
    "df_4 = pd.concat([df_4, df_splitted_fallacies])\n",
    "df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['dataset']=4\n",
    "df_4 = df_4.loc[:,['dataset', 'text', 'logical_fallacies']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5_1 = df_5_1[['fact_checked_segment', 'logical_fallacies', 'article']]\n",
    "df_5_1 = df_5_1.rename(columns={'fact_checked_segment': 'text', 'article': 'source'})\n",
    "df_5_1['dataset'] = 5\n",
    "df_5_1 = df_5_1.loc[:,['dataset', 'text', 'logical_fallacies', 'source']]\n",
    "df_5_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5_2.head()\n",
    "\n",
    "df_5_2 = df_5_2[['claim', 'logical_fallacies']]\n",
    "df_5_2 = df_5_2.rename(columns={'claim': 'text' })\n",
    "df_5_2['dataset'] = 5\n",
    "df_5_2 = df_5_2.loc[:,['dataset', 'text', 'logical_fallacies']]\n",
    "df_5_2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6.head()\n",
    "df_6 = df_6.rename(columns={'text_only': 'text', 'labels_only': 'logical_fallacies'})\n",
    "df_6['dataset'] = 6\n",
    "df_6 = df_6.loc[:,['dataset', 'text', 'logical_fallacies']]\n",
    "df_6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_8.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8.head()\n",
    "df_8 = df_8.dropna()\n",
    "df_8 = df_8.rename(columns={'claim': 'text' })\n",
    "df_8['dataset'] = 8\n",
    "df_8 = df_8.loc[:,['dataset', 'text', 'logical_fallacies']]\n",
    "df_8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9 = df_9[['text', 'fallacy']]\n",
    "df_9 = df_9.rename(columns={'fallacy': 'logical_fallacies' })\n",
    "df_9['dataset'] = 9\n",
    "df_9 = df_9.loc[:,['dataset', 'text', 'logical_fallacies']]\n",
    "df_9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lower case, underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adjust(data):\n",
    "    data['logical_fallacies']=data['logical_fallacies'].map(lambda x: x.lower().replace(' ', '_'))\n",
    "    return data\n",
    "\n",
    "df_1 = adjust(df_1)\n",
    "df_2 = adjust(df_2)\n",
    "df_3 = adjust(df_3)\n",
    "df_4 = adjust(df_4)\n",
    "df_5_1 = adjust(df_5_1)\n",
    "df_5_2= adjust(df_5_2)\n",
    "df_6 = adjust(df_6)\n",
    "df_8 = adjust(df_8)\n",
    "df_9 = adjust(df_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfList = [df_1, df_2, df_3, df_4 ,df_5_1, df_5_2, df_8, df_9]\n",
    "# for d in dfList:\n",
    "#     print (d.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1, df_2, df_3, df_4, df_5_1, df_5_2, df_6, df_8, df_9])\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['logical_fallacies']!='to_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['logical_fallacies']!='intentional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_list = df['logical_fallacies'].unique().tolist()\n",
    "fall_list.sort()\n",
    "fall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels ={\n",
    "    'none_of_the_above': 'none',\n",
    "    '_ad_hominem': 'ad_hominem',\n",
    "    '_hasty_generalization':'hasty_generalization',\n",
    "    '_appeal_to_ridicule': 'appeal_to_ridicule',\n",
    "    '_false_dilemma': 'false_dilemma',\n",
    "    '_appeal_to_fear':'appeal_to_fear',\n",
    "    'no_fallacy': 'none',\n",
    "    'straw_man': 'strawman',\n",
    "    'appeal_to_fear': 'appeal_to_emotion',\n",
    "    'appeal_to_anger': 'appeal_to_emotion',\n",
    "    'appeal_to_pity': 'appeal_to_emotion',\n",
    "    'appeal_to_positive_emotion': 'appeal_to_emotion',\n",
    "    'appeal_to_(false)_authority' : 'appeal_to_authority',\n",
    "    'false_authority': 'appeal_to_authority',\n",
    "    'hasty_generalization': 'faulty_generalization'\n",
    "}\n",
    "\n",
    "df= df.replace(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df, y ='logical_fallacies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('logical_fallacies')['logical_fallacies'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#https://docs.python.org/3/library/re.html\n",
    "\n",
    "#administration \\' s\n",
    "# \\n\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove POST\n",
    "    #text = re.sub(r'^.*?POST:', '', text, flags=re.DOTALL)\n",
    "    # Remove any remaining \"POST:\" occurrences\n",
    "    #text = re.sub(r'POST:', '', text)\n",
    "    # Remove '\\r\\n' and extra whitespace\n",
    "    #text = re.sub(r'\\r\\n', ' ', text)\n",
    "    # Remove '\\n'\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\r', '', text)\n",
    "    # Remove \" in beginning of text\n",
    "    text = re.sub(r'^\"', '', text)\n",
    "    # Remove \" at end of text\n",
    "    text = re.sub(r'\"$', '', text)\n",
    "     # Remove ' in beginning of text\n",
    "    text = re.sub(r\"^'\", '', text)\n",
    "    # Remove ' at end of text\n",
    "    text = re.sub(r\"'$\", '', text)\n",
    "    # Remove (number or text) at beginning of text\n",
    "    text = re.sub(r\"^\\([^)]*\\)\", '', text)\n",
    "    # Remove \\x80\\x9d\n",
    "    text = re.sub(r'\\x80\\x9d', '', text)\n",
    "     # Remove : in beginning of text\n",
    "    text = re.sub(r\"^:\", '', text)\n",
    "    # Remove · in beginning of text\n",
    "    text = re.sub(r\"^•\", '', text)\n",
    "    # Remove ” in beginning of text\n",
    "    text = re.sub(r\"^”\", '', text)\n",
    "    # Remove @user\n",
    "    text = re.sub(r'@user', '', text)\n",
    "    # Remove [main_tweet], [user104337]\n",
    "    text = re.sub(r\"\\[main_tweet\\]\", '', text)\n",
    "    text = re.sub(r\"\\[user\\d+\\]\", '', text)\n",
    "     # Remove punctuation\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text.strip()\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1641, \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"hallo \\r chocolatecake\"\n",
    "\n",
    "#Check if the string starts with 'hello':\n",
    "#x = re.sub(r\"\\[user\\d+\\]\", '', txt)\n",
    "x = re.sub(r'\\r', '', txt)\n",
    "# x = re.sub(r\"^\\[[^)]*\\]\", '', txt)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicated = df[df.duplicated([\"text\", \"logical_fallacies\"], keep=False)==True]\n",
    "df_duplicated = df_duplicated.sort_values(by='text')\n",
    "df_duplicated.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['text', 'logical_fallacies'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(['text']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(['text', 'logical_fallacies']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dataset'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select fallacies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('logical_fallacies')['logical_fallacies'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "most_freq_fallacies = df.groupby('logical_fallacies')['logical_fallacies'].value_counts().sort_values(ascending=False).index[:6]\n",
    "most_freq_fallacies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['logical_fallacies'].isin(most_freq_fallacies)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2[\"logical_fallacies\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the following words and clean extra spaces\n",
    "words_to_remove = ['uspoli', 'cdnpoli', 'pnpcbc', 'UKpolitics', 'auspol', 'polcan', 'eupol', 'nzpol', 'ctvpp']\n",
    "pattern = r'\\b(' + '|'.join(map(re.escape, words_to_remove)) + r')\\b'\n",
    "\n",
    "df_clean2[\"text\"] = df_clean2[\"text\"].str.replace(pattern, '', regex=True).str.replace(r'\\s+', ' ', regex=True).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one word texts and drop rows that do not make sense, e.g., testtesttesttest or are redundant\n",
    "df_clean2 = df_clean2.drop(index=17908) #tessttetttetete\t\n",
    "df_clean2 = df_clean2.drop(index=18030) # tesforArgumentforAr\n",
    "df_clean2 = df_clean2.drop(index=17573) # duplicate: yes\n",
    "df_clean2 = df_clean2.drop(index=18337) # duplicate: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "df_filtered = df_clean2[df_clean2['text'].str.split().str.len() == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at duplicate text\n",
    "df_duplicated_text = df_clean2[df_clean2.duplicated([\"text\"], keep=False)==True]\n",
    "df_duplicated_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df_clean2 = df_clean2.drop_duplicates(subset=['text'], keep=False)\n",
    "df_clean2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2.to_csv(\"../data/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
